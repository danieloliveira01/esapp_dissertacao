import streamlit as st
import pandas as pd
import numpy as np
from transformers import XLNetTokenizer, XLNetModel
import torch
#from keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
#from keras.preprocessing.sequence import pad_sequences
import json
import tensorflow as tf
from keras.models import load_model
from huggingface_hub import hf_hub_download

def focal_loss(gamma=2., alpha=None):
    def focal_loss_fixed(y_true, y_pred):
        y_true = tf.cast(y_true, tf.int32)
        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[-1])

        y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1. - K.epsilon())  # Prevenindo log(0)
        cross_entropy = -y_true * tf.math.log(y_pred)

        if alpha is not None:
            alpha_tensor = tf.constant(alpha, dtype=tf.float32)
            alpha_factor = y_true * alpha_tensor
            cross_entropy *= alpha_factor

        weight = tf.pow(1. - y_pred, gamma)  # Focal loss weight
        loss = weight * cross_entropy

        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1))
    return focal_loss_fixed
#setando a configura√ß√£o da pagina
st.set_page_config(page_title="ESApp - Estimador Autom√°tico de Pontos de Hist√≥ria", layout="wide", page_icon="üéØ")



def fibonacci_sequence(n):
    fib_sequence = [0, 1]
    while fib_sequence[-1] < n:
        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])
    return fib_sequence

def proximo_fibonacci(valor):
    fib_sequence = fibonacci_sequence(valor)
    for fib in fib_sequence:
        if fib >= valor:
            return fib
    return None


# Fun√ß√£o para carregar o arquivo de acur√°cia por classe
def carregar_acuracia_por_classe(lang):
    if lang == "en":
        with open('model/en/acuracia_por_classe_deep_learning.json', 'r') as f:
            acuracia_dict = json.load(f)
        return acuracia_dict
    if lang == "pt":
        with open('model/pt/acuracia_por_classe_deep_learning.json', 'r') as f:
            acuracia_dict = json.load(f)
        return acuracia_dict 


# Fun√ß√£o para carregar o modelo XLNet e o tokenizer
def carregar_xlnet_modelo():
    tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')
    model = XLNetModel.from_pretrained('xlnet-base-cased')
    return tokenizer, model

# Fun√ß√£o para gerar embeddings com o XLNet
def gerar_embeddings_xlnet(texto, tokenizer, model, max_length=512):
    inputs = tokenizer(texto, return_tensors='pt', truncation=True, padding=True, max_length=max_length)
    with torch.no_grad():
        outputs = model(**inputs)
    # Pegando o embedding da √∫ltima camada [CLS] token (ou o embedding m√©dio, se preferir)
    embeddings = outputs.last_hidden_state.mean(dim=1).numpy()
    return embeddings


def estimar_classificacao_deep_learning(lang, texto, modelo_rf, tokenizer, model_xlnet, max_sequence_length=512):
    embeddings = gerar_embeddings_xlnet(texto, tokenizer, model_xlnet, max_length=max_sequence_length)
    # Defina o n√∫mero de senten√ßas
    num_sentences = 115
    num_samples = embeddings.shape[0]
    embedding_dim = embeddings.shape[1]
   
    
    
    history = embeddings.reshape(embeddings.shape[0], 1, embeddings.shape[1])
    acuracia_dict = carregar_acuracia_por_classe(lang)
    estimativa = modelo_rf.predict(history)
    story_point = np.argmax(estimativa[0])
    acuracia = acuracia_dict.get(str(story_point), 0)

    if story_point == 0:
         estimative = "Facil"
    elif story_point == 1:
         estimative = "Medio"
    else:
         estimative = "Dificil"

    return estimative, acuracia


# Fun√ß√£o de estimativa usando o Random Forest (ap√≥s a convers√£o em embeddings)
def estimar_ponto_por_historia_random_forest(lang, texto, modelo_rf, tokenizer, model_xlnet, max_sequence_length=512):
    # Gerando embeddings com XLNet
    embeddings = gerar_embeddings_xlnet(texto, tokenizer, model_xlnet, max_length=max_sequence_length)
    acuracia_dict = carregar_acuracia_por_classe(lang)
    
   
    # Passando os embeddings para o modelo Random Forest para prever o ponto
    estimativa = modelo_rf.predict(embeddings)
    estimativa_fib = proximo_fibonacci(estimativa[0])
     # Obter a acur√°cia da classe predita
    acuracia = acuracia_dict.get(str(estimativa_fib), 0)
    # Aqui voc√™ pode ajustar para estimar com base no valor predito
    return estimativa_fib, acuracia







#Calculando a sequencia de fibonacci 
def fibonacci_sequence(n):
    fib_sequence = [0, 1]
    while fib_sequence[-1] < n:
        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])
    return fib_sequence
#Estimar os pontos por hist√≥ria com base no resultado do modelo.
def proximo_fibonacci(valor):
    fib_sequence = fibonacci_sequence(valor)
    for fib in fib_sequence:
        if fib >= valor:
            return fib
    return None

# Fun√ß√£o para estimar ponto por hist√≥ria, onde recebera como parametro, o modelo compilado, texto, tokenizer e tamanho max.
#tokenizer serve para realizar a tokeniza√ß√£o do texto, ou seja, selecionar as palavras de maior relevancia.
def estimar_ponto_por_historia_deep(texto, modelo, tokenizer, max_sequence_length):

    texto = [texto]
    encSequences_test = tokenizer.texts_to_sequences(texto)
    x_test = pad_sequences(encSequences_test, maxlen=max_sequence_length, padding='post')
    previsao = modelo.predict(x_test, batch_size=None, verbose=0, steps=None)
    estimativa = previsao[0][0]
    return estimativa

#Carregando o modelo e o tokenizer
#modelo = joblib.load('model/model_LSTM.joblib')
modelo = ""
df = pd.read_csv('data/reqTxt.csv', header=None)
dfRequire = df.iloc[:, :]
X = dfRequire[0]
X = np.array(X)

MAX_LEN = 23313
tokenizer = Tokenizer(num_words=MAX_LEN, char_level=False, lower=False)
tokenizer.fit_on_texts(X)
MAX_SEQUENCE_LENGTH = 100

st.sidebar.title("Selecione o modelo de estimativa")
option_model = st.sidebar.selectbox("Escolha o m√©todo de estimativa do ponto por hist√≥ria:", ("Classificacao - en", "Classificacao - pt", "Num√©rico - en", "Num√©rico - pt" ))
lang = ""
if option_model == "Classificacao - en":
     
     model_path = hf_hub_download(repo_id="DanielOS/ESApp-models", filename="en/model_classificacao_v1_05_25_en.h5")
     #modelo = load_model('model/en/model_classificacao_v1_05_25_en.h5', custom_objects={'focal_loss_fixed': focal_loss(gamma=2., alpha=None)})
     modelo = load_model(model_path,custom_objects={'focal_loss_fixed': focal_loss(gamma=2., alpha=None)} )
     #definir modelo random forest
     #modelo = joblib.load('model/en/deep_learning_classificacao.pkl')
     #modelo = load_model('model/en/model_classificacao_v1_05_25_en.h5', custom_objects={'focal_loss_fixed': focal_loss(gamma=2., alpha=None)})
     lang = "en"

if option_model == "Classificacao - pt":
     #definir modelo random forest
     model_path = hf_hub_download(repo_id="DanielOS/ESApp-models", filename="pt/model_classificacao_v1_05_25_pt.h5")
     
     #modelo = load_model('model/pt/model_classificacao_v1_05_25_pt.h5', custom_objects={'focal_loss_fixed': focal_loss(gamma=2., alpha=None)})
     modelo = load_model(model_path, custom_objects={'focal_loss_fixed': focal_loss(gamma=2., alpha=None)})
     lang = "pt"
    

if option_model == "Num√©rico - en":
     #definir modelo random forest
     #modelo = joblib.load('model/en/deep_learning_regressao.pkl')

     model_path = hf_hub_download(repo_id="DanielOS/ESApp-models", filename="en/model_deep_learning_regressao_en.h5")
     modelo = load_model(model_path, custom_objects={
                       'mse': tf.keras.losses.MeanSquaredError()
                   })
     ang = "en"

if option_model == "Num√©rico - pt":
     #definir modelo random forest
     #modelo = joblib.load('model/pt/deep_learning_pt.pkl')
     model_path = hf_hub_download(repo_id="DanielOS/ESApp-models", filename="pt/model_deep_learning_regressao_pt.h5")
     modelo = load_model(model_path, custom_objects={
                       'mse': tf.keras.losses.MeanSquaredError()
                   })
     lang = "pt"
#Gerando a interface do WebApp com Streamlit
st.title('üéØ ESApp - Estimador Autom√°tico de Pontos de Hist√≥ria')
st.markdown("""
Bem-vindo ao ESApp! Esta ferramenta ajuda voc√™ a estimar pontos de hist√≥ria automaticamente usando um modelo de aprendizado de m√°quina.
Voc√™ pode inserir uma descri√ß√£o de hist√≥ria de usu√°rio individualmente ou carregar um arquivo CSV com v√°rias hist√≥rias.
""")
# Inicializando vari√°veis no st.session_state
if 'estimativa' not in st.session_state:
    st.session_state.estimativa = None
if 'correcao' not in st.session_state:
    st.session_state.correcao = 0

if 'df_uploaded' not in st.session_state:
    st.session_state.df_uploaded = None
#Sidebar par selecionar a op√ß√£o de entrada, podendo ser hist√≥ria de usu√°rio unica ou um arquivo csv com v√°rias.
st.sidebar.title("Op√ß√µes de Entrada")
option = st.sidebar.radio("Escolha o m√©todo de entrada:", ("Inserir Manualmente", "Carregar Arquivo CSV"))
if 'estimativa' not in st.session_state:
    st.session_state.estimativa = None
if option == "Inserir Manualmente":
    # Se√ß√£o para entrada manual de descri√ß√£o de hist√≥ria
    st.subheader('Inserir Hist√≥ria de Usu√°rio Individualmente')
    user_input = st.text_area("Insira a descri√ß√£o da hist√≥ria:")
    user_input = user_input.replace(",", "")

    if st.button("Estimar Ponto por Hist√≥ria"):
        if user_input:
            
            #spinner para carregar enquanto processa.
            if lang == "":
                 lang = "en"
            if "Num√©rico" in option_model:
                with st.spinner('Estimando ponto por hist√≥ria...'):
                    
                    st.session_state.estimativa = estimar_ponto_por_historia_deep(user_input, modelo, tokenizer, MAX_SEQUENCE_LENGTH)
                    
                st.success(f"Ponto por hist√≥ria sugerido: {st.session_state.estimativa:.1f}")
                if lang == "en":
                        st.info(f"Este modelo possui um erro m√©dio de 3.77 na assertividade")
                if lang == "pt":
                        st.info(f"Este modelo possui um erro m√©dio de 3.94 na assertividade")
               
                
            if "Classificacao" in option_model:
                with st.spinner('Estimando ponto por hist√≥ria...'):
                    tokenizer, model_xlnet = carregar_xlnet_modelo()
                    #st.session_state.estimativa, st.session_state.acuracia = estimar_ponto_por_historia_random_forest(lang, user_input, modelo, tokenizer, model_xlnet)
                    st.session_state.estimativa, st.session_state.acuracia = estimar_classificacao_deep_learning(lang, user_input, modelo, tokenizer, model_xlnet)
                    
                    
                    #st.session_state.estimativa = estimar_ponto_por_historia_deep(user_input, modelo, tokenizer, MAX_SEQUENCE_LENGTH)
                st.success(f"Ponto por hist√≥ria sugerido: {st.session_state.estimativa}")
                #st.info(f"Para esta estimativa, este modelo possui: {st.session_state.acuracia:.1f}% de assertividade")
                st.info(f"Para esta estimativa, este modelo possui: {st.session_state.acuracia:.1f}% de assertividade")
            # Mostrar a estimativa inicial
            #st.success(f"Ponto por hist√≥ria sugerido: {estimativa}")

            # Adicionar campo para o usu√°rio corrigir a estimativa

    # Passo 2: Adicionar Corre√ß√£o Manual e Salvar
            
            st.session_state.correcao = st.number_input("Se a estimativa est√° incorreta, insira o ponto correto aqui:", min_value=1)

    if st.button("Salvar Corre√ß√£o"):
                        
                        if st.session_state.correcao != st.session_state.estimativa:
                            
                            with open('correcoes.csv', 'a') as f:
                                f.write(f"{user_input},{st.session_state.estimativa},{st.session_state.correcao}\n")
                            st.success("Corre√ß√£o salva com sucesso!")
                        else:
                            st.write(st.session_state.correcao)
                            st.write(st.session_state.estimativa)
                            st.warning("A corre√ß√£o √© igual √† estimativa original. N√£o foi necess√°rio salvar.")     
elif option == "Carregar Arquivo CSV":
    #Carregar o arquivo CSV
    st.subheader('Carregar Arquivo CSV com Hist√≥rias de Usu√°rios')
    #aqui, explicando como deve ser o arquivo
    st.markdown("""
    **Formato do arquivo CSV:**
    - Deve conter pelo menos tr√™s colunas: ID, T√≠tulo e Hist√≥ria.
    """)

    #Gerando um exemplo de arquivo para o usu√°rio fazer download.
    example_csv = pd.DataFrame({
        'ID': [1, 2],
        'T√≠tulo': ['Login no Sistema', 'Gerenciamento de Usu√°rios'],
        'Hist√≥ria': [
            'Como usu√°ria, quero poder fazer login no sistema para acessar minhas informa√ß√µes pessoais.',
            'Como administrador, quero poder gerenciar os usu√°rios para manter o sistema organizado e seguro.'
        ]
    })
    csv = example_csv.to_csv(index=False).encode('utf-8')

    # Bot√£o para download do exemplo de CSV
    st.download_button(
        label="Baixar Exemplo de Arquivo CSV",
        data=csv,
        file_name='exemplo_historias.csv',
        mime='text/csv'
    )

    uploaded_file = st.file_uploader("Escolha um arquivo CSV", type="csv")

    if st.button("Estimar Pontos por Hist√≥rias"):
        if uploaded_file:
            df_uploaded = pd.read_csv(uploaded_file)
            if len(df_uploaded.columns) < 3:
                st.error("O arquivo CSV deve ter pelo menos tr√™s colunas (ID, T√≠tulo, Hist√≥ria).")
            else:
                with st.spinner('Estimando pontos por hist√≥rias...'):
                    historias = df_uploaded.iloc[:, 2].tolist()
                    if "Num√©rico" in option_model:
                        estimativas = [estimar_ponto_por_historia_deep(historia, modelo, tokenizer, MAX_SEQUENCE_LENGTH) for historia in historias]
                        if lang == "en":
                            st.info(f"Este modelo possui um erro m√©dio de 3.77 na assertividade")
                        if lang == "pt":
                            st.info(f"Este modelo possui um erro m√©dio de 3.91 na assertividade")
                        
                        st.session_state.df_uploaded = df_uploaded.copy()
                        st.session_state.df_uploaded['estimativa'] = estimativas
                    if  "Classificacao" in option_model :

                        tokenizer, model_xlnet = carregar_xlnet_modelo()
                        #st.session_state.estimativa, st.session_state.acuracia = estimar_ponto_por_historia_random_forest(lang, user_input, modelo, tokenizer, model_xlnet)
                        #st.session_state.estimativa, st.session_state.acuracia = estimar_classificacao_deep_learning(lang, user_input, modelo, tokenizer, model_xlnet)
                        
                        
                        #tokenizer, model_xlnet = carregar_xlnet_modelo()
                        #resultados = [estimar_ponto_por_historia_random_forest(lang, historia, modelo, tokenizer, model_xlnet) for historia in historias]
                        resultados = [estimar_classificacao_deep_learning(lang, historia, modelo, tokenizer, model_xlnet) for historia in historias]
                        estimativas, acuracias = zip(*resultados)
                        print("estimativa:", estimativas)

        
                        #st.info(f"Para esta estimativa, este modelo possui: {st.session_state.acuracia:.1f}% de assertividade")
                   
                        st.session_state.df_uploaded = df_uploaded.copy()
                        st.session_state.df_uploaded['estimativa'] = estimativas
                        st.session_state.df_uploaded['acuracia'] = acuracias
                   
                    # Inicializando corre√ß√µes com as estimativas iniciais
                    st.session_state.correcoes = list(estimativas).copy()
                st.success("Estimativas geradas com sucesso!")
                st.write(st.session_state.df_uploaded)

                
                # Permitir download do arquivo com estimativas
                csv = st.session_state.df_uploaded.to_csv(index=False).encode('utf-8')
                st.download_button("Baixar CSV com Estimativas", data=csv, file_name="estimativas.csv", mime='text/csv')

                # Op√ß√£o para corre√ß√£o manual das estimativas
            st.subheader('Corre√ß√£o Manual das Estimativas')
            correcoes = []
        correcoes_estimativas = []
        for i in range(len(st.session_state.df_uploaded)):
            if "Classificacao" in option_model:
                 x = st.selectbox(
                    f"Corre√ß√£o para ID {st.session_state.df_uploaded.iloc[i, 0]} (Estimativa Original: {st.session_state.df_uploaded.iloc[i, -1]}):",
                    options=["Facil", "Medio", "Dificil"],
                    index=["Facil", "Medio", "Dificil"].index(st.session_state.correcoes[i]) if st.session_state.correcoes[i] in ["Facil", "Medio", "Dificil"] else 0,
                    key=f"correcao_{i}"
                )
            else:
                x = st.number_input(f"Corre√ß√£o para ID {st.session_state.df_uploaded.iloc[i, 0]} (Estimativa Original: {st.session_state.df_uploaded.iloc[i, -1]}):", min_value=0, value=int(st.session_state.correcoes[i]), key=f"correcao_{i}")
            st.session_state.correcoes[i] = x
        # Atualizando o DataFrame com as corre√ß√µes
        st.session_state.df_uploaded['Corre√ß√£o'] = st.session_state.correcoes

        # Permitir download do arquivo com estimativas e corre√ß√µes
        csv_corrigido = st.session_state.df_uploaded.to_csv(index=False).encode('utf-8')
        st.download_button("Baixar CSV com Estimativas e Corre√ß√µes", data=csv_corrigido, file_name="estimativas_corrigidas.csv", mime='text/csv')
    
    else:
            st.warning("Por favor, carregue um arquivo CSV contendo as hist√≥rias.")

# Adicionar link para documenta√ß√£o ou ajuda adicional
st.sidebar.markdown("Para mais informa√ß√µes, visite a [documenta√ß√£o](https://link_tese_mestrado).")


# Adicionar √≠cone de ajuda com tooltip sobre o formato do arquivo CSV
if option == "Carregar Arquivo CSV":
    st.sidebar.markdown("""
        <style>
        .info-icon {
            display: inline-flex;
            align-items: center;
        }
        .info-icon img {
            margin-right: 5px;
            
        }
        </style>
        <div class="info-icon">
            <img src="https://img.icons8.com/ios-filled/50/000000/info.png" width="20" height="20">
            <span>Formato do Arquivo CSV</span>
        </div>
        """, unsafe_allow_html=True)
    st.sidebar.info("""
    O arquivo CSV deve conter pelo menos tr√™s colunas: ID, T√≠tulo e Hist√≥ria. 

    """)
st.sidebar.markdown("""
---
**Nota:** A estimativa apresentada √© baseada em um modelo de aprendizado de m√°quina para auxiliar o time de desenvolvimento. √â recomendada uma an√°lise adicional pelo time para valida√ß√£o e ajustes necess√°rios.
""")
